constants {
    logging-queue-size-interval = 30000
    num-worker-per-node = 2
    data-volume-per-node = 10
    max-resolution-rows = 2000
    max-resolution-columns = 2000
    status-update-interval = 500
}

monitoring {
    monitoring-enabled = true
    monitoring-interval-ms = 3000
}

reshape {
    skew-handling-enabled = true
    skew-detection-initial-delay-ms = 5000
    skew-detection-interval-ms = 3000
    eta-threshold = 100
    tau-threshold = 100
    helper-overload-threshold = 300
    max-workload-samples-controller = 500
    workload-sample-size = 2000
    max-workload-samples-worker = 500
    first-phase-sharing-numerator = 9
    first-phase-sharing-denominator = 10
}

flow-control {
    credit-based-flow-control-enabled = true
    unprocessed-batches-limit-per-worker-pair = 100
    local-sending-buffer-limit-per-receiver = 100
    credit-poll-request-initial-delay-in-ms = 200
    credit-poll-request-interval-in-ms = 200
}

scheduling {
    policy-name = "all-ready-regions"
    time-slot-expiration-duration-ms = 5000
}

network-buffering {
    default-batch-size = 400
    enable-adaptive-buffering = true
    adaptive-buffering-timeout-ms = 500
}

reconfiguration {
    enable-transactional-reconfiguration = false
}

storage {
    # [memory, mongodb]
    mode = memory
    mongodb {
        url = "mongodb://localhost:27017"
        database = "texera_storage"
        commit-batch-size = 1000
    }
}

cache {
    # [false, true]
    enabled = true
}

user-sys {
    enabled = false
    googleClientId = ""
    version-time-limit-in-minutes = 60
    jwt {
        exp-in-days = 30
        256-bit-secret = random
    }
}

result-cleanup {
    ttl-in-seconds = 86400 # time to live for a collection is 2 days
    collection-check-interval-in-seconds = 86400 # 2 days
}

jdbc {
    url = "jdbc:mysql://localhost:3306/texera_db?serverTimezone=UTC"
    username = ""
    password = ""
}

web-server {
    workflow-state-cleanup-in-seconds = 30
    python-console-buffer-size = 100
    workflow-result-pulling-in-seconds = 3
}

fault-tolerance {
    enable-determinant-logging = false
    # [local, hdfs]
    log-storage-type = "local"
    log-flush-interval-ms = 0 # immediately flush
    log-record-max-size-in-byte = 67108864 #64MB
    # limit for resend buffer length, if the resend buffer
    # getting too large, the workflow aborts during recovery to avoid OOM.
    # TODO: Remove this after introducing checkpoints.
    max-supported-resend-queue-length = 10000
    delay-before-recovery = 3000
    hdfs-storage{
        address = "0.0.0.0:9870"
    }
}
