constants {
    logging-queue-size-interval = 30000
    num-worker-per-operator = 2
    max-resolution-rows = 2000
    max-resolution-columns = 2000
    status-update-interval = 500
}

flow-control {
    max-credit-allowed-in-bytes-per-channel = 1600000000  # -1 to disable flow control
    credit-poll-interval-in-ms = 200
}

network-buffering {
    default-data-transfer-batch-size = 400
    enable-adaptive-buffering = true
    adaptive-buffering-timeout-ms = 500
}

reconfiguration {
    enable-transactional-reconfiguration = false
}

cache {
    # [false, true]
    enabled = true
}

user-sys {
    enabled = false
    google {
        clientId = ""
        smtp {
            gmail = ""
            password = ""
        }
    }
    version-time-limit-in-minutes = 60
    jwt {
        exp-in-days = 30
        # generate the secret again for each deployment using the following:
        # 'openssl rand -hex 16'  or  'xxd -l16 -ps /dev/urandom'
        256-bit-secret = "8a1b2c3d4e5f6a7b8c9d0e1f2a3b4c5d"
    }
}

result-cleanup {
    ttl-in-seconds = 86400 # time to live for a collection is 2 days
    collection-check-interval-in-seconds = 86400 # 2 days
}

web-server {
    workflow-state-cleanup-in-seconds = 30
    python-console-buffer-size = 100
    workflow-result-pulling-in-seconds = 3
    clean-all-execution-results-on-server-start = false
}

fault-tolerance {
    # URI for storage, empty to disable logging.
    # Use absolute path only. for local file system, $AMBER_FOLDER will be interpolated to Amber folder path.
    # e.g. use "file://$AMBER_FOLDER/../log/recovery-logs/" for local logging.
    log-storage-uri = ""
    log-flush-interval-ms = 0 # immediately flush
    log-record-max-size-in-byte = 67108864 #64MB
    # limit for resend buffer length, if the resend buffer
    # getting too large, the workflow aborts during recovery to avoid OOM.
    # TODO: Remove this after introducing checkpoints.
    max-supported-resend-queue-length = 10000
    delay-before-recovery = 3000
    hdfs-storage{
        address = "0.0.0.0:9870"
    }
}

schedule-generator {
    enable-cost-based-schedule-generator = false
    use-global-search = false
    use-top-down-search = false
    search-timeout-milliseconds = 1000
}

python-language-server{
    provider = "pyright" # valid options: ["pyright", "pylsp"]
    port = 3000
    # Maximum number of retries for starting the language server.
    retry-counts = 3
    # Time in milliseconds to wait between retry attempts when starting the language server
    wait-time-ms = 200
}

ai-assistant-server{
    assistant = "none"
    # Put your Ai Service authentication key here
    ai-service-key = ""
    # Put your Ai service url here (If you are using OpenAI, then the url should be "https://api.openai.com/v1")
    ai-service-url = ""
}