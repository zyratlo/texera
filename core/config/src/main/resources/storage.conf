# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

# See PR https://github.com/Texera/texera/pull/3326 for configuration guidelines.
storage {
    result-storage-mode = iceberg # either mongodb or iceberg, mongodb will be deprecated soon
    result-storage-mode = ${?STORAGE_RESULT_MODE}

    # Configuration for Apache Iceberg, used for storing the workflow results & stats
    iceberg {
        catalog {
            type = hadoop # either hadoop, rest, or postgres
            type = ${?STORAGE_ICEBERG_CATALOG_TYPE}

            rest-uri = ""
            rest-uri = ${?STORAGE_ICEBERG_CATALOG_REST_URI} # the uri of the rest catalog, not needed unless using REST catalog

            postgres {
                # do not include scheme in the uri as Python and Java use different schemes
                uri-without-scheme = "localhost:5432/texera_iceberg_catalog"
                uri-without-scheme = ${?STORAGE_ICEBERG_CATALOG_POSTGRES_URI_WITHOUT_SCHEME}

                username = "texera"
                username = ${?STORAGE_ICEBERG_CATALOG_POSTGRES_USERNAME}

                password = "password"
                password = ${?STORAGE_ICEBERG_CATALOG_POSTGRES_PASSWORD}
            }
        }

        table {
            result-namespace = "operator-port-result"
            result-namespace = ${?STORAGE_ICEBERG_TABLE_RESULT_NAMESPACE}

            console-messages-namespace = "operator-console-messages"
            console-messages-namespace = ${?STORAGE_ICEBERG_TABLE_CONSOLE_MESSAGES_NAMESPACE}

            runtime-statistics-namespace = "workflow-runtime-statistics"
            runtime-statistics-namespace = ${?STORAGE_ICEBERG_TABLE_RUNTIME_STATISTICS_NAMESPACE}

            commit {
                batch-size = 4096 # decide the buffer size of our IcebergTableWriter
                batch-size = ${?STORAGE_ICEBERG_TABLE_COMMIT_BATCH_SIZE}

                # retry configures the OCC parameter for concurrent write operations in Iceberg
                # Docs about Reliability in Iceberg: https://iceberg.apache.org/docs/1.7.1/reliability/
                # Docs about full parameter list and their meaning: https://iceberg.apache.org/docs/1.7.1/configuration/#write-properties
                retry {
                    num-retries = 10
                    num-retries = ${?STORAGE_ICEBERG_TABLE_COMMIT_NUM_RETRIES}

                    min-wait-ms = 100
                    min-wait-ms = ${?STORAGE_ICEBERG_TABLE_COMMIT_MIN_WAIT_MS}

                    max-wait-ms = 10000
                    max-wait-ms = ${?STORAGE_ICEBERG_TABLE_COMMIT_MAX_WAIT_MS}
                }
            }
        }
    }

    # Configurations of the LakeFS & S3 for dataset storage;
    # Default values are provided for each field, which you don't need to change them if you deployed LakeFS+S3 via docker-compose.yml in file-service/src/main/resources/docker-compose.yml
    lakefs {
        endpoint = "http://localhost:8000/api/v1"
        endpoint = ${?STORAGE_LAKEFS_ENDPOINT}

        auth {
            api-secret = "random_string_for_lakefs"
            api-secret = ${?STORAGE_LAKEFS_AUTH_API_SECRET}

            username = "AKIAIOSFOLKFSSAMPLES"
            username = ${?STORAGE_LAKEFS_AUTH_USERNAME}

            password = "wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"
            password = ${?STORAGE_LAKEFS_AUTH_PASSWORD}
        }

        block-storage {
            type = "s3"
            type = ${?STORAGE_LAKEFS_BLOCK_STORAGE_TYPE}

            bucket-name = "texera-dataset"
            bucket-name = ${?STORAGE_LAKEFS_BLOCK_STORAGE_BUCKET_NAME}
        }
    }

    s3 {
        endpoint = "http://localhost:9000"
        endpoint = ${?STORAGE_S3_ENDPOINT}

        region = "us-west-2"
        region = ${?STORAGE_S3_REGION}

        multipart {
            part-size = "16MB"
            part-size = ${?STORAGE_S3_MULTIPART_PART_SIZE}
        }

        auth {
            username = "texera_minio"
            username = ${?STORAGE_S3_AUTH_USERNAME}

            password = "password"
            password = ${?STORAGE_S3_AUTH_PASSWORD}
        }
    }

    # Configuration for Postgres, used for user system data & metadata storage
    jdbc {
        url = "jdbc:postgresql://localhost:5432/texera_db?currentSchema=texera_db,public"
        url = ${?STORAGE_JDBC_URL}

        username = "postgres"
        username = ${?STORAGE_JDBC_USERNAME}

        password = ""
        password = ${?STORAGE_JDBC_PASSWORD}
    }
}